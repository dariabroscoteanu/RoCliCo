{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPTv2G55wfE6uxAsNHhaJwa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Please fill the following paths."],"metadata":{"id":"Up1yJMHyko8r"}},{"cell_type":"code","source":["# Path to the test dataset, containing \"digi.json\" and \"libertatea.json\"\n","TEST_PATH = \"\"\n","\n","# Path to the test dataset, containing \"protv.json\", \"cancan.json\" and \"wowbiz.json\"\n","TRAIN_PATH = \"\"\n","\n","# Path where the best accuracy checkpoint can be saved\n","CHECKPOINT_PATH =  \"\"\n","\n","# Path to the fasttext embedding downloaded from this link https://fasttext.cc/docs/en/pretrained-vectors.html \n","# Please download the file called \"cc.ro.300.vec\"\n","fasttext_embeddings_path = \"\" \n","\n","# Path to the folder in which the model and other necessary tools are saved\n","FOLDER_PATH = \"\""],"metadata":{"id":"0pIGlHUu9Ehm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Reading test and train datasets"],"metadata":{"id":"Rmhv8Mje9tId"}},{"cell_type":"code","source":["! pip install fasttext"],"metadata":{"id":"ZwpAyg3D9u6E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685967429504,"user_tz":-180,"elapsed":5247,"user":{"displayName":"Daria Broscoteanu","userId":"17692645243194726821"}},"outputId":"80a15fa0-92d2-4e5e-926f-a944c40d06e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: fasttext in /usr/local/lib/python3.10/dist-packages (0.9.2)\n","Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.10/dist-packages (from fasttext) (2.10.4)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.22.4)\n"]}]},{"cell_type":"code","source":["! pip install keras"],"metadata":{"id":"fnPxYNig9xAk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685967438714,"user_tz":-180,"elapsed":9213,"user":{"displayName":"Daria Broscoteanu","userId":"17692645243194726821"}},"outputId":"e11acc1e-4b6a-46bd-fe14-4d30b23f30b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.12.0)\n"]}]},{"cell_type":"code","source":["import tensorflow\n","from keras.layers import GlobalMaxPooling1D\n","from keras.regularizers import l2\n","from keras.models import Sequential\n","from keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Concatenate, Input, Flatten, Dropout, Bidirectional\n","from keras.models import Model\n","from keras.callbacks import ModelCheckpoint\n","\n","import numpy as np\n","from keras.preprocessing.text import Tokenizer\n","from keras.utils import pad_sequences\n","\n","import itertools\n","from sklearn.model_selection import train_test_split\n","import fasttext\n","from tensorflow.keras.utils import to_categorical\n","import os\n","import json\n","import pandas as pd\n","import pickle"],"metadata":{"id":"h2e2g9NqUfWy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_file(path, name):\n","  file_path = path + \"/\" + name \n","\n","  reader = open(file_path)\n","  json_array = json.load(reader)\n","  news = []\n","  # nonclickbait = 0\n","  # clickbait = 1\n","\n","  for element in json_array:\n","    cat = 1\n","    if element[\"category\"] == \"nonclickbait\":\n","      cat = 0\n","    item = {\n","        \"title\":element[\"title\"],\n","        \"content\":element[\"content\"],\n","        \"category\":cat\n","            }\n","    news.append(item)\n","\n","  return news"],"metadata":{"id":"lG9fbgsSj_mQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_raw_data(folder_path):\n","  filenames = sorted(os.listdir(folder_path))\n","\n","  raw_data = []\n","  for filename in filenames:\n","    print(filename)\n","    current = read_file(folder_path, filename)\n","    raw_data.extend(current)\n","\n","  return raw_data"],"metadata":{"id":"eNcQ0zKikAzo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Test files:')\n","test_raw_data  = read_raw_data(TEST_PATH)\n","print(\"---------------------\")\n","print('Train files:')\n","train_raw_data = read_raw_data(TRAIN_PATH)\n","print(\"---------------------\")"],"metadata":{"id":"0X9SBAUekCTX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = pd.DataFrame(train_raw_data)\n","df_test = pd.DataFrame(test_raw_data)"],"metadata":{"id":"aeZaDwsIlT_h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Classification."],"metadata":{"id":"b91-BLlA9y7M"}},{"cell_type":"code","source":["def load_fasttext_embeddings(filepath, word_index, embedding_dim):\n","    embeddings_index = {}\n","    with open(filepath, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            values = line.rstrip().rsplit(' ')\n","            word = values[0]\n","            coefs = np.asarray(values[1:], dtype='float32')\n","            embeddings_index[word] = coefs\n","\n","    embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n","    for word, i in word_index.items():\n","        embedding_vector = embeddings_index.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[i] = embedding_vector\n","\n","    return embedding_matrix"],"metadata":{"id":"H7JFzToq9yaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_length_title = 49\n","max_length_content = 9401 \n","embedding_dim = 300\n","max_words_title = 12000 \n","max_words_content = 25000 \n","input_shape_title = (max_length_title,)\n","input_shape_content = (max_length_content,)\n","output_shape = 2\n","num_classes = 2"],"metadata":{"id":"LQt0NHWX-Hb1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer_title = Tokenizer(num_words=max_words_title, lower=True)\n","tokenizer_title.fit_on_texts(df_train['title'])\n","\n","tokenizer_content = Tokenizer(num_words=max_words_content, lower=True)\n","tokenizer_content.fit_on_texts(df_train['content'])\n","\n","num_words_title = min(max_words_title, len(tokenizer_title.word_index) + 1)\n","num_words_content = min(max_words_content, len(tokenizer_content.word_index) + 1)\n","\n","X_title = tokenizer_title.texts_to_sequences(df_train['title'])\n","X_content = tokenizer_content.texts_to_sequences(df_train['content'])\n","\n","X_title = pad_sequences(X_title, maxlen=max_length_title, padding='post', truncating='post')\n","X_content = pad_sequences(X_content, maxlen=max_length_content, padding='post', truncating='post')"],"metadata":{"id":"I527rVLU9_vc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer_title_path = FOLDER_PATH + \"tokenizer_title.pickle\"\n","tokenizer_content_path = FOLDER_PATH + \"tokenizer_content.pickle\"\n","\n","with open(tokenizer_title_path, 'wb') as handle:\n","    pickle.dump(tokenizer_title, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","with open(tokenizer_content_path, 'wb') as handle:\n","    pickle.dump(tokenizer_title, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"metadata":{"id":"eAgOvTGopxl3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["title_words = dict(itertools.islice(tokenizer_title.word_index.items(), num_words_title))\n","content_words = dict(itertools.islice(tokenizer_content.word_index.items(), num_words_content))"],"metadata":{"id":"JrqEvrQOP0dT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["embedding_matrix_title = load_fasttext_embeddings(fasttext_embeddings_path, title_words, embedding_dim)\n","embedding_matrix_content = load_fasttext_embeddings(fasttext_embeddings_path, content_words, embedding_dim)"],"metadata":{"id":"aGzf_sUlP68L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Y = df_train[\"category\"].values\n","X_title_train, X_title_val, X_content_train, X_content_val, y_train, y_val = train_test_split(X_title, X_content, Y, test_size=0.2, shuffle=True)\n","y_train = to_categorical(y_train, num_classes)\n","y_val = to_categorical(y_val, num_classes)"],"metadata":{"id":"_SH5ZqzfP-7K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_epochs = 10\n","batch_size = 32 \n","\n","# input layers\n","\n","input_title = Input(shape=(max_length_title,))\n","input_content = Input(shape=(max_length_content,))\n","\n","#---------------------------------------------------------------------------------------------------------------------------\n","\n","# embedding layers\n","\n","embedding_title = Embedding(input_dim=num_words_title + 1, output_dim=embedding_dim, weights=[embedding_matrix_title], input_length=max_length_title, trainable=False)(input_title)\n","embedding_content = Embedding(input_dim=num_words_content + 1, output_dim=embedding_dim, weights=[embedding_matrix_content], input_length=max_length_content, trainable=False)(input_content)\n","\n","#---------------------------------------------------------------------------------------------------------------------------\n","\n","# lstm layers\n","\n","lstm_title = Bidirectional(LSTM(32, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))(embedding_title)\n","lstm_title_2 = Bidirectional(LSTM(32))(lstm_title)\n","\n","lstm_content = Bidirectional(LSTM(64, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))(embedding_content)\n","lstm_content_2 = Bidirectional(LSTM(64))(lstm_content)\n","\n","#---------------------------------------------------------------------------------------------------------------------------\n","\n","# pooling layers\n","\n","pooled_title = GlobalMaxPooling1D()(lstm_title)\n","pooled_content = GlobalMaxPooling1D()(lstm_content)\n","\n","#---------------------------------------------------------------------------------------------------------------------------\n","\n","# concatenation layer\n","\n","concatenated = Concatenate()([pooled_title, pooled_content])\n","\n","#---------------------------------------------------------------------------------------------------------------------------\n","\n","# fully connected and dropout layers\n","\n","fc1 = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(concatenated)\n","dropout1 = Dropout(0.6)(fc1)\n","\n","fc2 = Dense(64, activation='relu')(dropout1)\n","dropout2 = Dropout(0.6)(fc2)\n","\n","output = Dense(2, activation='softmax')(dropout2)\n","\n","#---------------------------------------------------------------------------------------------------------------------------"],"metadata":{"id":"nZhniE-uQC5r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Model(inputs=[input_title, input_content], outputs=output)\n","\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","model_bestAccuracyCheckpoint = ModelCheckpoint( \n","            filepath=CHECKPOINT_PATH,            \n","            monitor='val_accuracy',\n","            mode='max',\n","            save_weights_only=True,\n","            save_best_only=True\n","        )\n","\n","model.fit([X_title_train, X_content_train], y_train, validation_data=([X_title_val, X_content_val], y_val), epochs=num_epochs, batch_size=batch_size, callbacks=model_bestAccuracyCheckpoint)"],"metadata":{"id":"gA8x7OOvQ7RC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_weights(CHECKPOINT_PATH)"],"metadata":{"id":"0BRJJVdBRH9J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bilstm_model_path = FOLDER_PATH + \"bilstm_model\"\n","model.save(bilstm_model_path)"],"metadata":{"id":"7WquJugNq7SR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def predict_article(title, content, model, title_tokenizer, content_tokenizer):\n","  encoded_title = title_tokenizer.texts_to_sequences([title])\n","  encoded_text = content_tokenizer.texts_to_sequences([content])\n","\n","  max_length_title = 49 \n","  max_length_content = 9401 \n","  padded_title = pad_sequences(encoded_title, maxlen=max_length_title, padding='post')\n","  padded_text = pad_sequences(encoded_text, maxlen=max_length_content, padding='post')\n","\n","  class_probabilities = model.predict([padded_title, padded_text])[0]\n","\n","  predicted_label = np.argmax(class_probabilities)\n","\n","  return predicted_label"],"metadata":{"id":"dexy3rLwRO7K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def classify(df):\n","  predictions = []\n","  true_labels = []\n","  for index, row in df.iterrows():\n","    title = row[\"title\"]\n","    content = row[\"content\"]\n","    label_true = row[\"category\"]\n","    label_pred = predict_article(title, content, model, tokenizer_title, tokenizer_content)\n","    predictions.append(label_pred)\n","    true_labels.append(label_true)\n","\n","  return predictions, true_labels"],"metadata":{"id":"TRjgsPOMRlw6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds, trues = classify(df_test)"],"metadata":{"id":"uSCirZPURpcM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n","print(classification_report(trues, preds))"],"metadata":{"id":"VPlQOeUWRymL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","cm = confusion_matrix(trues, preds)\n","sns.set(font_scale=1.4) \n","sns.heatmap(cm, annot=True, cmap='Blues', cbar=False, fmt='g')\n","plt.xlabel('Predicted label')\n","plt.ylabel('True label')\n","plt.title('Confusion matrix')\n","plt.show()"],"metadata":{"id":"4-gju0vfR0CC"},"execution_count":null,"outputs":[]}]}