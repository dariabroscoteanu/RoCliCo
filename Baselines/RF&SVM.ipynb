{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0vXAYGYkBgb"
      },
      "source": [
        "### Please fill the following paths."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjqEdVGqkIkt"
      },
      "outputs": [],
      "source": [
        "# Path to the test dataset, containing \"digi.json\" and \"libertatea.json\"\n",
        "TEST_PATH = \"\"\n",
        "\n",
        "# Path to the test dataset, containing \"protv.json\", \"cancan.json\" and \"wowbiz.json\"\n",
        "TRAIN_PATH = \"\"\n",
        "\n",
        "# Path to the folder in which the model and other necessary tools are saved\n",
        "FOLDER_PATH = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX02ThC3qHBV"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3NIv6qwqVJf"
      },
      "outputs": [],
      "source": [
        "! pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJrd-q2_qF7V"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from copy import deepcopy\n",
        "import re\n",
        "from string import punctuation\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm,tqdm_notebook\n",
        "import matplotlib.pyplot as plt\n",
        "tqdm.pandas()\n",
        "\n",
        "from scipy import sparse\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "import pickle\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuVZWaTTqaKV"
      },
      "outputs": [],
      "source": [
        "import stanza\n",
        "stanza.download('ro')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbCVQPXEqco4",
        "outputId": "1c03a5db-9896-48cf-90a0-780779c8d2e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vFztXA0qAx_"
      },
      "source": [
        "### Reading test and train datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFu8x0xJqFFV"
      },
      "outputs": [],
      "source": [
        "def read_file(path, name):\n",
        "  file_path = path + \"/\" + name\n",
        "\n",
        "  reader = open(file_path)\n",
        "  json_array = json.load(reader)\n",
        "  news = []\n",
        "  # nonclickbait = 0\n",
        "  # clickbait = 1\n",
        "\n",
        "  for element in json_array:\n",
        "    cat = 1\n",
        "    if element[\"category\"] == \"nonclickbait\":\n",
        "      cat = 0\n",
        "    item = {\n",
        "        \"title\":element[\"title\"],\n",
        "        \"content\":element[\"content\"],\n",
        "        \"category\":cat\n",
        "            }\n",
        "    news.append(item)\n",
        "\n",
        "  return news"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeID7b8erUHt"
      },
      "outputs": [],
      "source": [
        "def read_raw_data(folder_path):\n",
        "  filenames = sorted(os.listdir(folder_path))\n",
        "\n",
        "  raw_data = []\n",
        "  for filename in filenames:\n",
        "    print(filename)\n",
        "    current = read_file(folder_path, filename)\n",
        "    raw_data.extend(current)\n",
        "\n",
        "  return raw_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDh7bJ7Nt9cz"
      },
      "outputs": [],
      "source": [
        "print('Test files:')\n",
        "test_raw_data  = read_raw_data(TEST_PATH)\n",
        "print(\"---------------------\")\n",
        "print('Train files:')\n",
        "train_raw_data = read_raw_data(TRAIN_PATH)\n",
        "print(\"---------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5NS5AOZvxGz"
      },
      "outputs": [],
      "source": [
        "df_train = pd.DataFrame(train_raw_data)\n",
        "df_test = pd.DataFrame(test_raw_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N68oWia-wUIC"
      },
      "source": [
        "### Feature extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVIH8H27wZnG"
      },
      "outputs": [],
      "source": [
        "# the stopwords list is taken from this url: https://countwordsfree.com/stopwords/romanian\n",
        "# the words used in questions are removed from this list\n",
        "romanian_stopwords = ['acea', 'aceasta', 'această', 'aceea', 'acei', 'aceia', 'acel', 'acela', 'acele', 'acelea', 'acest', 'acesta', 'aceste', 'acestea', 'aceşti', 'aceştia', 'acolo', 'acord', 'acum', 'ai', 'aia', 'aibă', 'aici', 'al', 'ăla', 'ale', 'alea', 'ălea', 'altceva', 'altcineva', 'am', 'ar', 'are', 'aş', 'aşadar', 'asemenea', 'asta', 'ăsta', 'astăzi', 'astea', 'ăstea', 'ăştia', 'asupra', 'aţi', 'au', 'avea', 'avem', 'aveţi', 'azi', 'bine', 'bucur', 'bună', 'ca', 'că', 'căci', 'când', 'care', 'cărei', 'căror', 'cărui', 'cât', 'câte', 'câţi', 'către', 'câtva', 'caut', 'ce', 'cel', 'ceva', 'chiar', 'cinci', 'cînd', 'cine', 'cineva', 'cît', 'cîte', 'cîţi', 'cîtva', 'contra', 'cu', 'cum', 'cumva', 'curând', 'curînd', 'da', 'dă', 'dacă', 'dar', 'dată', 'datorită', 'dau', 'de', 'deci', 'deja', 'deoarece', 'departe', 'deşi', 'din', 'dinaintea', 'dintr-', 'dintre', 'doi', 'doilea', 'două', 'drept', 'după', 'ea', 'ei', 'el', 'ele', 'eram', 'este', 'eşti', 'eu', 'face', 'fără', 'fata', 'fi', 'fie', 'fiecare', 'fii', 'fim', 'fiţi', 'fiu', 'frumos', 'graţie', 'halbă', 'iar', 'ieri', 'îi', 'îl', 'îmi', 'împotriva', 'în', 'înainte', 'înaintea', 'încât', 'încît', 'încotro', 'între', 'întrun', 'întruna', 'întrucât', 'întrucît', 'îţi', 'la', 'lângă', 'le', 'li', 'lîngă', 'lor', 'lui', 'mă', 'mai', 'mâine', 'mea', 'mei', 'mele', 'mereu', 'meu', 'mi', 'mie', 'mîine', 'mine', 'mult', 'multă', 'mulţi', 'mulţumesc', 'ne', 'nevoie', 'nicăieri', 'nici', 'nimeni', 'nimeri', 'nimic', 'nişte', 'noastră', 'noastre', 'noi', 'noroc', 'noştri', 'nostru', 'nouă', 'nu', 'opt', 'ori', 'oricând', 'oricare', 'oricât', 'orice', 'oricînd', 'oricine', 'oricît', 'oricum', 'oriunde', 'până', 'patra', 'patru', 'patrulea', 'pe', 'pentru', 'peste', 'pic', 'pînă', 'poate', 'pot', 'prea', 'prima', 'primul', 'prin', 'puţin', 'puţina', 'puţină', 'rog', 'sa', 'să', 'săi', 'sale', 'şapte', 'şase', 'sau', 'său', 'se', 'şi', 'sînt', 'sîntem', 'sînteţi', 'spate', 'spre', 'ştiu', 'sub', 'sunt', 'suntem', 'sunteţi', 'sută', 'ta', 'tăi', 'tale', 'tău', 'te', 'ţi', 'ţie', 'timp', 'tine', 'toată', 'toate', 'tot', 'toţi', 'totuşi', 'trei', 'treia', 'treilea', 'tu', 'un', 'una', 'unde', 'undeva', 'unei', 'uneia', 'unele', 'uneori', 'unii', 'unor', 'unora', 'unu', 'unui', 'unuia', 'unul', 'vă', 'vi', 'voastră', 'voastre', 'voi', 'voştri', 'vostru', 'vouă', 'vreme', 'vreo', 'vreun', 'zece', 'zero', 'zi', 'zice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7bahDGjwmh0"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "  result = text.replace('/',\"\").replace('\\n','')\n",
        "  result = re.sub(r'[0-9]+','număr',result)\n",
        "  result = re.sub(r'(\\w)(\\1{2,})',r'\\1',result)\n",
        "  result = re.sub(r'(?x)\\b(?=\\w*\\d)\\w+\\s*', '', result)\n",
        "  result = result.lower()\n",
        "  punctuations = punctuation + \"„”\"\n",
        "  result = \"\".join(word for word in result if word not in punctuations)\n",
        "  re.sub(r' +',' ',result).lower().strip()\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1NYcmb9woXP"
      },
      "outputs": [],
      "source": [
        "question_words = [\"ce\", \"cine\", \"cui\", \"care\", \"căruia\", \"căreia\", \"cărora\", \"căruia\", \"cât\", \"cît\", \"câți\", \"câtă\", \"câte\", \"câtor\", \"cum\", \"oare\"]\n",
        "\n",
        "def isquestion(text):\n",
        "    result = text.lower().split()\n",
        "    if result[0] in question_words:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rnQWlzMwwOK"
      },
      "outputs": [],
      "source": [
        "def count_num_stopwords(text):\n",
        "  result = preprocess(text)\n",
        "  words = result.split()\n",
        "  count = len([word for word in words if word not in romanian_stopwords])\n",
        "  return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQyslnXLwxaM"
      },
      "outputs": [],
      "source": [
        "# RIX = num_long_words / num_sentences\n",
        "\n",
        "def compute_RIX(text):\n",
        "  number_of_sentences = len(sent_tokenize(text))\n",
        "  result = preprocess(text)\n",
        "  words = result.split()\n",
        "\n",
        "  words = [word.lower() for word in words]\n",
        "  words = [word for word in words if len(word) > 7]\n",
        "\n",
        "  rix = 0\n",
        "\n",
        "  if number_of_sentences != 0:\n",
        "    rix = len(words) / float(number_of_sentences)\n",
        "  else:\n",
        "    rix = 0\n",
        "\n",
        "  return rix\n",
        "\n",
        "\n",
        "# LIX = num_words / num_sentences + (100 * num_long_words) / num_words\n",
        "def compute_LIX(text):\n",
        "  number_of_sentences = len(sent_tokenize(text))\n",
        "  result = preprocess(text)\n",
        "  words = result.split()\n",
        "\n",
        "  words = [word.lower() for word in words]\n",
        "  w = len(words)\n",
        "  words = [word for word in words if len(word) > 7]\n",
        "  long_words = len(words)\n",
        "\n",
        "  v1 = v2 = 0\n",
        "  if number_of_sentences != 0:\n",
        "    v1 = w / float(number_of_sentences)\n",
        "\n",
        "  if w != 0:\n",
        "    v2 = (100 * long_words) / float(w)\n",
        "\n",
        "  lix = v1 + v2\n",
        "\n",
        "  return lix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjAvrbIwwzd9"
      },
      "outputs": [],
      "source": [
        "nlp = stanza.Pipeline('ro', processors='tokenize,pos', tokenize_no_ssplit=True)\n",
        "\n",
        "def extract_pos_tags(text):\n",
        "  doc = nlp(text)\n",
        "\n",
        "  pos_tags = []\n",
        "\n",
        "  for sentence in doc.sentences:\n",
        "    for word in sentence.words:\n",
        "      pos_tags.append((word.text, word.upos))\n",
        "  return pos_tags\n",
        "\n",
        "\n",
        "def compute_proper_nouns_number(pos_tags):\n",
        "  num_pnouns = 0\n",
        "  for word, pos in pos_tags:\n",
        "    if pos == 'PROPN':\n",
        "      num_pnouns += 1\n",
        "  return num_pnouns\n",
        "\n",
        "\n",
        "def compute_fmeasure(pos_tags):\n",
        "  noun_freq = 0\n",
        "  adj_freq = 0\n",
        "  prep_freq = 0\n",
        "  article_freq = 0\n",
        "  pronoun_freq = 0\n",
        "  verb_freq = 0\n",
        "  adv_freq = 0\n",
        "  interj_freq = 0\n",
        "\n",
        "  for word, pos in pos_tags:\n",
        "      if word.lower() in ['oh', 'wow', 'hmm', 'uh', 'um']:\n",
        "          interj_freq += 1\n",
        "      elif \"NOUN\" in pos:\n",
        "          noun_freq += 1\n",
        "      elif \"ADJ\" in pos:\n",
        "          adj_freq += 1\n",
        "      elif \"ADP\" in pos:\n",
        "            prep_freq += 1\n",
        "      elif word.lower() in ['un', 'o', 'niște', 'acest', 'această', 'acești', 'aceste', 'al', 'ai', 'ale']:\n",
        "          article_freq += 1\n",
        "      elif 'PRON' in pos and not 'PUNCT' in pos:\n",
        "          pronoun_freq += 1\n",
        "      elif 'VERB' in pos:\n",
        "          verb_freq += 1\n",
        "      elif 'ADV' in pos:\n",
        "          adv_freq += 1\n",
        "\n",
        "  f_measure = (noun_freq + adj_freq + prep_freq + article_freq) / 2 - (pronoun_freq + verb_freq + adv_freq + interj_freq + 100) / 2\n",
        "\n",
        "  return f_measure\n",
        "\n",
        "\n",
        "def compute_cls_score_ro(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    num_words = 0\n",
        "    num_sentences = 0\n",
        "    for sent in doc.sentences:\n",
        "        num_words += len(sent.words)\n",
        "        num_sentences += 1\n",
        "\n",
        "    avg_letters_per_100_words = sum(len(word.text) for sent in doc.sentences for word in sent.words) / num_words * 100\n",
        "    avg_sentences_per_100_words = num_sentences / num_words * 100\n",
        "\n",
        "    cls_score = 0.0588 * avg_letters_per_100_words - 0.296 * avg_sentences_per_100_words - 15.8\n",
        "\n",
        "    return cls_score\n",
        "\n",
        "\n",
        "\n",
        "def count_common_nouns(title, text):\n",
        "   title_doc = nlp(title)\n",
        "   text_doc = nlp(text)\n",
        "\n",
        "   title_nouns = set(word.text for sent in title_doc.sentences for word in sent.words if word.upos == 'NOUN')\n",
        "   common_noun_count = sum(1 for sent in text_doc.sentences for word in sent.words if word.text in title_nouns and word.upos == 'NOUN')\n",
        "\n",
        "   return common_noun_count\n",
        "\n",
        "\n",
        "def count_proper_nouns(title, text):\n",
        "  title_doc = nlp(title)\n",
        "  text_doc = nlp(text)\n",
        "\n",
        "  title_nouns = set(word.text for sent in title_doc.sentences for word in sent.words if word.upos == 'PROPN')\n",
        "  proper_noun_count = sum(1 for sent in text_doc.sentences for word in sent.words if word.text in title_nouns and word.upos == 'PROPN')\n",
        "\n",
        "  return proper_noun_count\n",
        "\n",
        "\n",
        "\n",
        "def count_propers_and_common(title, text):\n",
        "  title_doc = nlp(title)\n",
        "  text_doc = nlp(text)\n",
        "\n",
        "  commons = set()\n",
        "  propers = set()\n",
        "\n",
        "  for sent in title_doc.sentences:\n",
        "    for word in sent.words:\n",
        "      if word.upos == 'PROPN':\n",
        "        propers.add(word.text)\n",
        "      elif word.upos == 'NOUN':\n",
        "        commons.add(word.text)\n",
        "\n",
        "\n",
        "  count_common = 0\n",
        "  count_proper = 0\n",
        "\n",
        "  for sent in text_doc.sentences:\n",
        "    for word in sent.words:\n",
        "        if word.text in propers and word.upos == 'PROPN':\n",
        "          count_proper += 1\n",
        "        elif word.text in commons and word.upos == 'NOUN':\n",
        "          count_common += 1\n",
        "\n",
        "  return count_common, count_proper\n",
        "\n",
        "\n",
        "def get_pos_title(title):\n",
        "  title_doc = nlp(title)\n",
        "  pos_result = []\n",
        "  for sent in title_doc.sentences:\n",
        "    for word in sent.words:\n",
        "      pos_result.append(word.upos)\n",
        "\n",
        "  result = \" \".join(pos_result)\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k038TERw8ka"
      },
      "outputs": [],
      "source": [
        "def punctuation_patterns(title):\n",
        "    patterns = ['!?', '...', '***', '!!!', '???', '(', ')', '$']\n",
        "    found = False\n",
        "    counts = {}\n",
        "    for pattern in patterns:\n",
        "        if pattern in title:\n",
        "          found = True\n",
        "          break\n",
        "\n",
        "    return found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy2v6LWcw_Fy"
      },
      "outputs": [],
      "source": [
        "def extract_data_from_pos_tags(title, content):\n",
        "  title_doc = nlp(title)\n",
        "  text_doc = nlp(content)\n",
        "\n",
        "  commons = set()\n",
        "  propers = set()\n",
        "\n",
        "  noun_freq = 0\n",
        "  adj_freq = 0\n",
        "  prep_freq = 0\n",
        "  article_freq = 0\n",
        "  pronoun_freq = 0\n",
        "  verb_freq = 0\n",
        "  adv_freq = 0\n",
        "  interj_freq = 0\n",
        "\n",
        "  num_proper_words_title = 0\n",
        "\n",
        "  for sent in title_doc.sentences:\n",
        "    for word in sent.words:\n",
        "      if word.upos == 'PROPN':\n",
        "        propers.add(word.text)\n",
        "        num_proper_words_title += 1\n",
        "      elif word.upos == 'NOUN':\n",
        "        commons.add(word.text)\n",
        "\n",
        "\n",
        "      pos = word.upos\n",
        "      if word.text.lower() in ['oh', 'wow', 'hmm', 'uh', 'um']:\n",
        "          interj_freq += 1\n",
        "      elif \"NOUN\" in pos:\n",
        "          noun_freq += 1\n",
        "      elif \"ADJ\" in pos:\n",
        "          adj_freq += 1\n",
        "      elif \"ADP\" in pos:\n",
        "            prep_freq += 1\n",
        "      elif word.text.lower() in ['un', 'o', 'niște', 'acest', 'această', 'acești', 'aceste', 'al', 'ai', 'ale']:\n",
        "          article_freq += 1\n",
        "      elif 'PRON' in pos and not 'PUNCT' in pos:\n",
        "          pronoun_freq += 1\n",
        "      elif 'VERB' in pos:\n",
        "          verb_freq += 1\n",
        "      elif 'ADV' in pos:\n",
        "          adv_freq += 1\n",
        "\n",
        "  count_common = 0\n",
        "  count_proper = 0\n",
        "\n",
        "  num_words = 0\n",
        "  num_sentences = 0\n",
        "  num_long_words = 0\n",
        "  len_words = 0\n",
        "  for sent in text_doc.sentences:\n",
        "    num_sentences += 1\n",
        "    for word in sent.words:\n",
        "        num_words += 1\n",
        "        len_words += len(word.text)\n",
        "        if word.text in propers and word.upos == 'PROPN':\n",
        "          count_proper += 1\n",
        "        elif word.text in commons and word.upos == 'NOUN':\n",
        "          count_common += 1\n",
        "\n",
        "        if len(word.text) > 7:\n",
        "          num_long_words += 1\n",
        "\n",
        "  f_measure = (noun_freq + adj_freq + prep_freq + article_freq) / 2 - (pronoun_freq + verb_freq + adv_freq + interj_freq + 100) / 2\n",
        "\n",
        "  if num_words != 0:\n",
        "    avg_letters_per_100_words = len_words / num_words * 100\n",
        "    avg_sentences_per_100_words = num_sentences / num_words * 100\n",
        "  else:\n",
        "    avg_letters_per_100_words = 0\n",
        "    avg_sentences_per_100_words = 0\n",
        "\n",
        "  cls_score = 0.0588 * avg_letters_per_100_words - 0.296 * num_sentences - 15.8\n",
        "\n",
        "  return count_common, count_proper, num_proper_words_title, f_measure, cls_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFBtcTJSxGIJ"
      },
      "outputs": [],
      "source": [
        "def extract_data(df):\n",
        "  commons = []\n",
        "  propers = []\n",
        "  proper_words_title = []\n",
        "  f_measures = []\n",
        "  cls_scores = []\n",
        "  for index, row in df.iterrows():\n",
        "    count_common, count_proper, num_proper_words_title, f_measure, cls_score = extract_data_from_pos_tags(row['title'], row['content'])\n",
        "    commons.append(count_common)\n",
        "    propers.append(count_proper)\n",
        "    proper_words_title.append(num_proper_words_title)\n",
        "    f_measures.append(f_measure)\n",
        "    cls_scores.append(cls_score)\n",
        "\n",
        "  return commons, propers, proper_words_title, f_measures, cls_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kscsNduVxZi7"
      },
      "outputs": [],
      "source": [
        "def create_data_frame(df):\n",
        "  new_df = pd.DataFrame()\n",
        "\n",
        "  # independent title features\n",
        "  new_df[\"processed_title\"]    = df['title'].progress_apply(preprocess)\n",
        "  new_df[\"is_question\"]        = df['title'].progress_apply(isquestion)\n",
        "  new_df[\"num_words\"]          = df['title'].progress_apply(lambda x: len(x.split()))\n",
        "  new_df[\"rix_title\"]          = df['title'].progress_apply(compute_RIX)\n",
        "  new_df[\"lix_title\"]          = df['title'].progress_apply(compute_LIX)\n",
        "  new_df[\"num_stopwords\"]      = df['title'].progress_apply(count_num_stopwords)\n",
        "  new_df[\"punct_patterns\"]     = df[\"title\"].progress_apply(punctuation_patterns)\n",
        "  new_df[\"stop_word_ratio\"]    = new_df['num_stopwords']/new_df['num_words']\n",
        "  new_df[\"pos_title\"]          = df['title'].progress_apply(get_pos_title)\n",
        "\n",
        "  # title + content common features\n",
        "  commons, propers, proper_words_title, f_measures, cls_scores = extract_data(df)\n",
        "  new_df[\"num_proper_words\"]   = proper_words_title\n",
        "  new_df[\"fmeasure_title\"]     = f_measures\n",
        "  new_df[\"clscore\"]            = cls_scores\n",
        "  new_df[\"commons\"]            = commons\n",
        "  new_df[\"propers\"]            = propers\n",
        "\n",
        "  # content features\n",
        "  new_df[\"rix_content\"]         = df['content'].progress_apply(compute_RIX)\n",
        "  new_df[\"lix_content\"]         = df['content'].progress_apply(compute_LIX)\n",
        "\n",
        "  new_df[\"category\"]            = df['category']\n",
        "\n",
        "  return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHqyR5PMJoFP"
      },
      "outputs": [],
      "source": [
        "def generate_processed_dataframes(df_train, df_test):\n",
        "  df_processed_train =  create_data_frame(df_train)\n",
        "  df_processed_test =  create_data_frame(df_test)\n",
        "\n",
        "  y_test = df_processed_test['category']\n",
        "  df_processed_test = df_processed_test.drop('category', axis=1)\n",
        "\n",
        "  y_train = df_processed_train['category']\n",
        "  df_processed_train = df_processed_train.drop('category', axis=1)\n",
        "\n",
        "  return y_test, df_processed_test, y_train, df_processed_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5D_I2hQJ7-2"
      },
      "outputs": [],
      "source": [
        "y_test, df_processed_test, y_train, df_processed_train = generate_processed_dataframes(df_train, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u3eZHp-NvR1"
      },
      "outputs": [],
      "source": [
        "def process_title(train_titles, test_titles):\n",
        "  tfidf = TfidfVectorizer(\n",
        "    min_df=3,\n",
        "    max_features=None,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    ngram_range=(1,5),\n",
        "    use_idf=True,\n",
        "    smooth_idf=True,\n",
        "    sublinear_tf=True\n",
        "    )\n",
        "\n",
        "  x_train_headline = tfidf.fit_transform(train_titles)\n",
        "  x_test_headline  = tfidf.transform(test_titles)\n",
        "\n",
        "  tfidf_path = FOLDER_PATH + \"tfidf.pkl\"\n",
        "  with open(tfidf_path, 'wb') as handle:\n",
        "    pickle.dump(tfidf, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "  return x_train_headline, x_test_headline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Up4-7U8YONW7"
      },
      "outputs": [],
      "source": [
        "def process_pos_title(train_titles, test_titles):\n",
        "  cv_pos = CountVectorizer()\n",
        "  sc_pos = StandardScaler(with_mean=False)\n",
        "\n",
        "  x_train_pos = cv_pos.fit_transform(train_titles)\n",
        "  x_train_pos_sc = sc_pos.fit_transform(x_train_pos)\n",
        "\n",
        "  x_test_pos = cv_pos.transform(test_titles)\n",
        "  x_test_pos_sc = sc_pos.transform(x_test_pos)\n",
        "\n",
        "  cv_pos_path = FOLDER_PATH + \"cv_pos.pkl\"\n",
        "  sc_pos_path = FOLDER_PATH + \"sc_pos.pkl\"\n",
        "\n",
        "  with open(cv_pos_path, 'wb') as handle:\n",
        "    pickle.dump(cv_pos, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "  with open(sc_pos_path, 'wb') as handle:\n",
        "    pickle.dump(sc_pos, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "  return x_train_pos_sc, x_test_pos_sc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXnpiIAoOyaU"
      },
      "outputs": [],
      "source": [
        "def process_numerical_values(x_train_val, x_test_val):\n",
        "  sc_val = StandardScaler()\n",
        "  x_train_val_sc = sc_val.fit_transform(x_train_val)\n",
        "  x_test_val_sc = sc_val.transform(x_test_val)\n",
        "\n",
        "  sc_val_path = FOLDER_PATH + \"sc_val.pkl\"\n",
        "\n",
        "  with open(sc_val_path, 'wb') as handle:\n",
        "    pickle.dump(sc_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "  return x_train_val_sc, x_test_val_sc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbbzkFh5OlOb"
      },
      "outputs": [],
      "source": [
        "x_train_headline, x_test_headline = process_title(df_processed_train['processed_title'], df_processed_test['processed_title'])\n",
        "x_train_pos_sc, x_test_pos_sc = process_pos_title(df_processed_train['pos_title'], df_processed_test['pos_title'])\n",
        "\n",
        "x_train_val = df_processed_train.drop(columns=['processed_title','pos_title']).values\n",
        "x_test_val = df_processed_test.drop(columns=['processed_title','pos_title']).values\n",
        "\n",
        "x_train_val_sc, x_test_val_sc = process_numerical_values(x_train_val, x_test_val)\n",
        "\n",
        "x_train = sparse.hstack([x_train_headline, x_train_pos_sc, x_train_val_sc]).tocsr()\n",
        "x_test  = sparse.hstack([x_test_headline,  x_test_pos_sc,  x_test_val_sc] ).tocsr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mo_g3-2f4425"
      },
      "source": [
        "### Training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbJVrbJ847de"
      },
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier(bootstrap=True, class_weight='balanced', criterion='entropy', max_depth=None, max_features='auto',\n",
        "                             max_leaf_nodes=None, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "                             n_estimators=150, n_jobs=-1, oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
        "linear_svc = LinearSVC()\n",
        "logistic_regression = LogisticRegression(random_state=0, solver=\"newton-cg\")\n",
        "svc = SVC()\n",
        "\n",
        "models = [\n",
        "    rfc,\n",
        "    linear_svc,\n",
        "    logistic_regression,\n",
        "    svc\n",
        "]\n",
        "\n",
        "cross_validation_split = 5\n",
        "cv_df = pd.DataFrame(index=range(cross_validation_split * len(models)))\n",
        "entries = []\n",
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "  accuracies = cross_val_score(model, x_train, y_train, scoring='accuracy', cv=cross_validation_split)\n",
        "  for fold_idx, accuracy in enumerate(accuracies):\n",
        "    entries.append((model_name, fold_idx, accuracy))\n",
        "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJf5lsOe5BS_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "sns.boxplot(x='model_name', y='accuracy',\n",
        "            data=cv_df,\n",
        "            color='lightblue',\n",
        "            showmeans=True)\n",
        "plt.title(\"MEAN ACCURACY (cross_validation_split = 5)\", size=14);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ooz-unkW5Cw6"
      },
      "outputs": [],
      "source": [
        "cv_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI16kARd6rmO"
      },
      "outputs": [],
      "source": [
        "rfc = RandomForestClassifier(bootstrap=True, class_weight='balanced', criterion='entropy', max_depth=None, max_features='auto',\n",
        "                             max_leaf_nodes=None, min_impurity_decrease=0.0, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "                             n_estimators=150, n_jobs=-1, oob_score=True, random_state=0, verbose=0, warm_start=False)\n",
        "\n",
        "rfc.fit(x_train,y_train)\n",
        "y_pred= rfc.predict(x_test)\n",
        "print(metrics.classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gz1ZAtu0pMP_"
      },
      "outputs": [],
      "source": [
        "rfc_path =  FOLDER_PATH + \"rfc_model.pkl\"\n",
        "with open(rfc_path, 'wb') as f:\n",
        "    pickle.dump(rfc, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9oN6VmF6xoQ"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', cbar=False, fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion matrix - Random Forest')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lrelZfNEte0H"
      },
      "outputs": [],
      "source": [
        "clf = svm.SVC(kernel='linear',probability=True)\n",
        "\n",
        "clf.fit(x_train, y_train)\n",
        "y_pred_model_svm = clf.predict_proba(x_test)\n",
        "y_pred_labels_svm = clf.predict(x_test)\n",
        "print(metrics.classification_report(y_test, y_pred_labels_svm, digits=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0Y0JDQrtt3W"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred_labels_svm)\n",
        "sns.set(font_scale=1.4)\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', cbar=False, fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion matrix - SVM')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
